{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Graph-based semisupervised learning\n",
        "\n",
        "This is a brief demo of graph-based semi-supervised learning using the [Graph Learning](https://github.com/jwcalder/GraphLearning) package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install -q graphlearning annoy"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first consider the two-moons data set. The red stars are the locations of the labeled nodes. See how well you can do with one label per moon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import graphlearning as gl\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets\n",
        "\n",
        "#Draw data randomly and build a k-nearest neighbor graph with k=10 neighbors\n",
        "X,labels = datasets.make_moons(n_samples=500,noise=0.1)\n",
        "W = gl.weightmatrix.knn(X,10)\n",
        "\n",
        "#Generate training data\n",
        "train_ind = gl.trainsets.generate(labels, rate=3)\n",
        "train_labels = labels[train_ind]\n",
        "\n",
        "#Semi-supervsied learning\n",
        "model = gl.ssl.laplace(W)\n",
        "pred_labels = model.fit_predict(train_ind, train_labels)\n",
        "\n",
        "#Compute accuracy\n",
        "accuracy = gl.ssl.ssl_accuracy(pred_labels, labels, train_ind)\n",
        "print(\"Accuracy: %.2f%%\"%accuracy)\n",
        "\n",
        "#Make plots\n",
        "plt.figure()\n",
        "plt.scatter(X[:,0],X[:,1], c=pred_labels)\n",
        "plt.scatter(X[train_ind,0],X[train_ind,1], c='r', marker='*', s=100)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now run an experiment classifying MNIST digits. We first load the dataset and display some images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "\n",
        "#Load MNIST data\n",
        "data,labels = gl.datasets.load('mnist')\n",
        "\n",
        "#Display images\n",
        "gl.utils.image_grid(data,n_rows=16,n_cols=16)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's try some semi-supervised learning on MNIST. We'll show the results of Laplace learning and graph nearest neighbors. The methods available in the package are listed in the documentation here: https://jwcalder.github.io/GraphLearning/ssl.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "\n",
        "W = gl.weightmatrix.knn('mnist', 10)\n",
        "D = gl.weightmatrix.knn('mnist', 10, kernel='distance')\n",
        "\n",
        "num_train_per_class = 100\n",
        "train_ind = gl.trainsets.generate(labels, rate=num_train_per_class)\n",
        "train_labels = labels[train_ind]\n",
        "\n",
        "models = [gl.ssl.graph_nearest_neighbor(D), gl.ssl.laplace(W)]\n",
        "\n",
        "for model in models:\n",
        "    pred_labels = model.fit_predict(train_ind,train_labels)\n",
        "    accuracy = gl.ssl.ssl_accuracy(labels,pred_labels,train_ind)\n",
        "    print(model.name + ': %.2f%%'%accuracy)\n",
        "\n",
        "#Plot some of the misclassified images and their labels\n",
        "ind_incorrect = labels != pred_labels\n",
        "gl.utils.image_grid(data[ind_incorrect,:],title='Misclassified')\n",
        "print(pred_labels[ind_incorrect][:10])\n",
        "print(labels[ind_incorrect][:10])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now give an example of image denoising using graph-based regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "from scipy.sparse import identity\n",
        "\n",
        "#Load and subsample cow image\n",
        "img = gl.datasets.load_image('cow')\n",
        "img = img[::2,::2]\n",
        "m,n,c = img.shape\n",
        "\n",
        "#Add noise to image\n",
        "img_noisy = np.clip(img + 0.05*np.random.randn(m,n,c),0,1)\n",
        "\n",
        "#Plot clean and noisy image\n",
        "plt.figure()\n",
        "plt.imshow(img,vmin=0,vmax=1)\n",
        "plt.title('Clean Cow')\n",
        "plt.figure()\n",
        "plt.imshow(img_noisy,vmin=0,vmax=1)\n",
        "plt.title('Noisy Cow')\n",
        "\n",
        "#Denoise with graph-based regression\n",
        "lam = 10\n",
        "eps=5\n",
        "eps_f=0.15\n",
        "\n",
        "#Build graph\n",
        "x,y = np.mgrid[:m,:n]\n",
        "x,y = x.flatten(),y.flatten()\n",
        "X = np.vstack((x,y)).T\n",
        "\n",
        "#Features of image (pixels)\n",
        "Y = np.reshape(img_noisy,(m*n,c))\n",
        "W = gl.weightmatrix.epsilon_ball(X,eps,features=Y,epsilon_f=eps_f)\n",
        "G = gl.graph(W)\n",
        "L = G.laplacian()\n",
        "\n",
        "#Denoising\n",
        "U = gl.utils.conjgrad(identity(m*n) + lam*L,Y)\n",
        "img_denoised = np.reshape(U,(m,n,c))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img_denoised,vmin=0,vmax=1)\n",
        "plt.title('Denoised Cow')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##Exercise\n",
        "\n",
        "1. Try playing around with the label rate above. How do things work for 1 label per class?\n",
        "2. Choose another graph from [GraphLearning](https://jwcalder.github.io/GraphLearning/datasets.html#graphlearning.datasets.load_graph) to try Laplace learning on. For example, try PubMed.\n",
        "3. Write a function label propagation (i.e., gradient descent) to solve the Laplace learning equation, as described in the book. Can you achieve higher accuracy by stopping early?"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}