{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multidimensional Scaling (MDS) \n",
        "\n",
        "This notebook gives a brief introduction to Multidimensional Scaling (MDS). Let us first define some helper functions that will compute MDS for us and install graphlearning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install -q graphlearning"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "#Classical multidimensional scaling \n",
        "def mds(H,k=2,center=False):\n",
        "\n",
        "    #Only center for distance matrices\n",
        "    if center:\n",
        "        n = H.shape[0]\n",
        "        J = np.eye(n) - (1/n)*np.ones((n,n))\n",
        "        H = -0.5*J@H@J\n",
        "\n",
        "    #Need to sort eigenvalues, since H may not be positive semidef\n",
        "    vals,V = sparse.linalg.eigsh(H,k=10*k,which='LM')\n",
        "    ind = np.argsort(-vals)\n",
        "    V = V[:,ind]\n",
        "    vals = vals[ind]\n",
        "\n",
        "    #Get top eigenvectors and square roots of positive parts of eigenvalues\n",
        "    P = V[:,:k]\n",
        "    S = np.maximum(vals[:k],0)**(1/2)\n",
        "\n",
        "    #Return MDS embedding\n",
        "    return P@np.diag(S)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first consider a couple of toy problems. Play around with the dimension parameters or come up with examples yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import graphlearning as gl\n",
        "from sklearn.metrics import pairwise\n",
        "import numpy as np\n",
        "\n",
        "#Toy data on the sphere in d dimensions\n",
        "n = 1000\n",
        "d = 3\n",
        "X = gl.utils.rand_ball(n,d)\n",
        "X = X/np.linalg.norm(X,axis=1)[:,None]\n",
        "\n",
        "#MDS using pairwise distances\n",
        "D = pairwise.euclidean_distances(X,squared=True)\n",
        "P = mds(D,k=2,center=True)\n",
        "plt.figure()\n",
        "plt.title('High dimensional sphere')\n",
        "plt.scatter(P[:,0],P[:,1])\n",
        "\n",
        "#Parabola in high dimensions\n",
        "n = 1000\n",
        "d = 10\n",
        "X = np.zeros((n,d))\n",
        "X[:,0] = np.linspace(-1,1,n)\n",
        "X[:,-1] = X[:,0]**2\n",
        "\n",
        "#MDS using pairwise distances\n",
        "D = pairwise.euclidean_distances(X,squared=True)\n",
        "P = mds(D,k=2,center=True)\n",
        "plt.figure()\n",
        "plt.title('Parabola')\n",
        "plt.scatter(P[:,0],P[:,1])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now run this on MNIST and compare to PCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Load MNIST data and subset to a random selection of 5000 images\n",
        "data, labels = gl.datasets.load('mnist')\n",
        "ind = np.random.choice(data.shape[0],size=5000)\n",
        "data = data[ind,:]\n",
        "labels = labels[ind]\n",
        "\n",
        "#Subset to a smaller number of digits\n",
        "num = 3   #Number of digits to use\n",
        "X = data[labels < num] #subset to 0s and 1s\n",
        "L = labels[labels < num] #corresponding labels\n",
        "\n",
        "#MDS\n",
        "S = pairwise.cosine_similarity(X)\n",
        "P = mds(S,k=2,center=False)\n",
        "plt.figure()\n",
        "plt.title('Cosine Similarity')\n",
        "plt.scatter(P[:,0],P[:,1],c=L,s=10)\n",
        "\n",
        "n = X.shape[0]\n",
        "E = pairwise.euclidean_distances(X,squared=True)/n\n",
        "S = np.exp(-E)\n",
        "P = mds(S,k=2,center=False)\n",
        "plt.figure()\n",
        "plt.title('Gaussian Similarity')\n",
        "plt.scatter(P[:,0],P[:,1],c=L,s=10)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "1. Apply MDS to another data set in graphlearning, like 'fashionmnist'.\n",
        "2. Apply MDS to an sklearn dataset.\n",
        "2. Compare against PCA and LDA from previous notebooks."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}