{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#k-Means Clustering\n",
        "This notebook gives some basic examples of k-means clustering, and an application to real data. While sklearn has a k-means clustering function, we will write our own, to make sure we understand the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def kmeans(X,k,visualize=False,T=200):\n",
        "    \"\"\"\n",
        "    k-means Clustering\n",
        "\n",
        "    Args:\n",
        "        X: nxm array of data, each row is a datapoint\n",
        "        k: Number of clusters\n",
        "        visualize: Whether to plot internal iterations\n",
        "        T: Max number of iterations\n",
        "\n",
        "    Returns:\n",
        "        Numpy array of labels obtained by binary k-means clustering\n",
        "    \"\"\"\n",
        "\n",
        "    #Number of data points\n",
        "    n = X.shape[0]\n",
        "\n",
        "    #Randomly choose initial cluster means\n",
        "    means = X[np.random.choice(n,size=k,replace=False),:]\n",
        "\n",
        "    #Initialize arrays for distances and labels\n",
        "    dist = np.zeros((k,n))\n",
        "    labels = np.zeros((n,))\n",
        "\n",
        "    #Main iteration for kmeans\n",
        "    num_changed = 1\n",
        "    i=0\n",
        "    while i < T and num_changed > 0:\n",
        "\n",
        "        #Update labels\n",
        "        old_labels = labels.copy()\n",
        "        for j in range(k):\n",
        "            dist[j,:] = np.sum((X - means[j,:])**2,axis=1)\n",
        "        labels = np.argmin(dist,axis=0)\n",
        "        num_changed = np.sum(labels != old_labels)\n",
        "\n",
        "        #Update means\n",
        "        for j in range(k):\n",
        "            means[j,:] = np.mean(X[labels==j,:],axis=0)\n",
        "\n",
        "        #Iterate counter\n",
        "        i+=1\n",
        "\n",
        "        #Plot result (red points are labels)\n",
        "        if visualize:\n",
        "            print('Iteration %d'%i)\n",
        "            plt.scatter(X[:,0],X[:,1], c=labels)\n",
        "            plt.scatter(means[:,0],means[:,1], c='r')\n",
        "            plt.pause(0.1)\n",
        "\n",
        "    return labels"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create some synthetic data and run k-means. Run it several times. Do you every see a poor clustering result?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sklearn.datasets as datasets\n",
        "\n",
        "n = 500\n",
        "X,L = datasets.make_blobs(n_samples=n, cluster_std=[1,1.5,0.5], random_state=60)\n",
        "labels = kmeans(X,3,visualize=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##Limits of k-means\n",
        "k-means has trouble with datasets where clusters are not generally spherical in shape, especially when different clusters have vastly different aspect ratios. An example is given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 500\n",
        "separation = 0.8\n",
        "X1 = np.random.randn(int(n/2),2)\n",
        "L1 = np.zeros((n,))\n",
        "X2 = np.random.randn(int(n/2),2)@np.array([[0.1,0],[0,10]]) + separation*np.array([3,0])\n",
        "L2 = np.ones((n,))\n",
        "\n",
        "X = np.vstack((X1,X2))\n",
        "L = np.hstack((L1,L2))\n",
        "\n",
        "labels = kmeans(X,2,visualize=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another interesting example is the famous two-moons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sklearn.datasets as datasets\n",
        "\n",
        "n=500\n",
        "X,L = datasets.make_moons(n_samples=n,noise=0.1)\n",
        "\n",
        "labels = kmeans(X,2,visualize=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##Real data\n",
        "We now consider using k-means to cluster MNIST digits. Let's install the [Graph Learning](https://github.com/jwcalder/GraphLearning) Python package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install -q graphlearning"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load MNIST data into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "\n",
        "data, labels = gl.datasets.load('mnist')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot some MNIST images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "gl.utils.image_grid(data, n_rows=10, n_cols=10, title='Some MNIST Images', fontsize=26)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Binary clustering problem witih 2 digits\n",
        "class1 = 0\n",
        "class2 = 1\n",
        "\n",
        "#Subset data to two digits\n",
        "I = labels == class1\n",
        "J = labels == class2\n",
        "X = data[I | J,:]\n",
        "L = labels[I | J]\n",
        "\n",
        "#Convert labels to 0/1\n",
        "I = L == class1\n",
        "L[I] = 0\n",
        "L[~I] = 1\n",
        "\n",
        "#kmeans clustering\n",
        "cluster_labels = kmeans(X, 2)\n",
        "\n",
        "#Check accuracy\n",
        "acc1 = np.mean(cluster_labels == L)\n",
        "acc2 = np.mean(cluster_labels != L)\n",
        "print('Clustering accuracy = %.2f%%'%(100*max(acc1,acc2)))\n",
        "\n",
        "#Show images from each cluster\n",
        "gl.utils.image_grid(X[cluster_labels==0,:], n_rows=10, n_cols=10, title='Cluster 1', fontsize=26)\n",
        "gl.utils.image_grid(X[cluster_labels==1,:], n_rows=10, n_cols=10, title='Cluster 2', fontsize=26)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Exercises\n",
        "1. Play around with changing the two digits to cluster. Which two digits are most difficult to cluster?\n",
        "2. Try k-means clustering with more than 2 classes. Try with 3, 4, or with the whole MNIST dataset. Computing accuracy is more challenging, since one has to account for all possible permutations of label values. Use the clustering_purity function below. Show image grids of each cluster.\n",
        "3. Try applying $k$-means to another data set, say FashionMNIST in graphlearning or one of the real-world data sets in sklearn.dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes purity of clustering.\n",
        "\n",
        "    Args:\n",
        "        y_true: True labels\n",
        "        y_pred: Predicted labels\n",
        "\n",
        "    Returns:\n",
        "        Clustering purity\n",
        "    \"\"\"\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
        "    return 100*np.sum(np.max(contingency_matrix, axis=0)) / np.sum(contingency_matrix)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for j in range(10):\n",
        "    gl.utils.image_grid(data[cluster_labels==j,:], n_rows=10, n_cols=10, title='Cluster %d'%j, fontsize=26)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}