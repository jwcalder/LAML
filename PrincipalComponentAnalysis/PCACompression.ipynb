{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#PCA-based image compression\n",
        "\n",
        "We consider here an application of PCA to image compression. We first load an image and show some of its trucated SVD's (for row-wise compression of the image matrix)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install -q graphlearning"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load an image and display it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "img = gl.datasets.load_image('chairtoy')\n",
        "plt.figure()\n",
        "plt.imshow(img)\n",
        "\n",
        "#Check data range and shape\n",
        "print('Pixel intensity range: (%d,%d)'%(img.min(),img.max()))\n",
        "print(img.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's display the truncated SVD. Since the $m\\times n$ data matrix $X$ below has far more columns than rows, i.e., $m \\ll n$, it is expensive to form the $n\\times n$ matrix $X^TX$ and find its top eigenvalues. In this case, an SVD is faster, using scipy.sparse.linalg.svds. \n",
        "\n",
        "As an aside, if you inspect the code of svds in scipy, it uses the eigensolver eigsh on $X^TX$, but it does it in such a way that the matrix $X^TX$ is never explicitly computed! The method is similar to the power iteration, using that you can compute $X^TX\\mathbf{x} = X^T(X\\mathbf{x})$ without ever forming $X^TX$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "X = np.hstack((img[:,:,0],img[:,:,1],img[:,:,2]))\n",
        "\n",
        "#SVD (order of singular values not guaranteed so we have to sort)\n",
        "t0 = time.time()\n",
        "P,S,QT = sparse.linalg.svds(X,k=500)\n",
        "print('SVD time: %.2f seconds'%(time.time()-t0))\n",
        "ind = np.argsort(-S)\n",
        "Q = QT[ind,:].T #Scipy returns the SVD transposed\n",
        "\n",
        "#Compare execution time to eigsh\n",
        "t0 = time.time()\n",
        "sparse.linalg.eigsh(X.T@X,k=500,which='LM')\n",
        "print('Eigs time: %.2f seconds'%(time.time()-t0))\n",
        "\n",
        "for k in [1,5,25,50,100,200]:\n",
        "    Xk = np.clip(X@Q[:,:k]@Q[:,:k].T,0,1)\n",
        "    imgk = np.stack((Xk[:,:512],Xk[:,512:1024],Xk[:,1024:]),axis=2)\n",
        "    plt.figure()\n",
        "    plt.imshow(imgk)\n",
        "    plt.title('%d Singular Vectors'%k)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For block-based compression, we'll convet the image to 8x8 patches. The image is 512x512 so this gives 4096 patches, each with 8x8x3=192 numbers (RGB for each pixel)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = 8\n",
        "X = gl.utils.image_to_patches(img,patch_size=(m,m))\n",
        "print(X.shape)\n",
        "grid = gl.utils.color_image_grid(X,n_rows=5,n_cols=10)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's do an SVD (or PCA) on the blocks. We show to top 50 singular vectors, which start out as slowly varying low frequencies, with the later singular vectors capturing fine scale details and texture in the image blocks. \n",
        "\n",
        "Here, the $m\\times n$ matrix $X$ has far more rows than columns, so $m \\gg n$. In this case, it is more efficient to compute $X^TX$, which is a smaller $n\\times n$ matrix and compute its eigenvectors, instead of performing an SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy import sparse\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "Vals, Q = sparse.linalg.eigsh(X.T@X,k=3*m*m-1,which='LM')\n",
        "Q_all = Q[:,::-1] #Eigenvalues are returned in opposite order\n",
        "print('Eigsh time: %.2f seconds'%(time.time()-t0))\n",
        "\n",
        "#SVD for comparison\n",
        "t0 = time.time()\n",
        "sparse.linalg.svds(X,k=3*m*m-1)\n",
        "print('SVD time: %.2f seconds'%(time.time()-t0))\n",
        "\n",
        "P = Q_all.T.copy()\n",
        "P = P - P.min()\n",
        "P = P/P.max()\n",
        "gl.utils.color_image_grid(P,n_rows=5,n_cols=10)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compress the image, we project the image blocks onto the top k singular vectors and the reconstruct the image from its blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for num_comps in [1,5,10,20,40,80]:\n",
        "\n",
        "    #Get top singular vectors\n",
        "    Q = Q_all[:,:num_comps]\n",
        "\n",
        "    #Compress and decompress the image\n",
        "    comp_X = X@Q\n",
        "    decomp_X = comp_X@Q.T\n",
        "\n",
        "    #Compute compression ration\n",
        "    comp_size = Q.shape[0]*Q.shape[1] + comp_X.shape[0]*comp_X.shape[1]\n",
        "    comp_ratio = X.shape[0]*X.shape[1]/comp_size\n",
        "\n",
        "    #Recontruct image from patches for visualization\n",
        "    img_comp = gl.utils.patches_to_image(decomp_X, (img.shape[0],img.shape[1]), patch_size=(m,m))\n",
        "    img_comp = np.clip(img_comp,0,1)\n",
        "\n",
        "    #Print PSNR\n",
        "    MSE = np.sum((X-decomp_X)**2)/X.shape[0]/X.shape[1]\n",
        "    PSNR = 10*np.log10(np.max(X)**2/MSE)\n",
        "    print('Compression ratio: %.1f:1, PSNR: %.1f'%(comp_ratio,PSNR))\n",
        "\n",
        "    #Plot compressed and difference image\n",
        "    img_diff = np.clip(img_comp - img + 0.5,0,1)\n",
        "    plt.figure()\n",
        "    plt.imshow(np.hstack((img_comp,img_diff)))\n",
        "    plt.title('Compression Raio: %.1f:1'%comp_ratio)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "1. Play around with different block sizes. What is the best for compression?\n",
        "2. Compare the PSNR for the original row-based compression with block-based compression. How does the PSNR compare at the same label rates. \n",
        "3. Generate a plot of the singular values for the image and the blocks. Which one decays faster? \n",
        "4. Project the blocks into two dimensions to visualize the block space. \n",
        "5. [Challenging] Write a compression algorithm that chooses the best singular vectors to use for each block, instead of the top $k$. To do this, choose a threshold $\\mu>0$, project the image blocks onto all of the singular vectors, and then discard (i.e., set to zero) any coefficient (i.e., PCA coordinate) that is smaller than $\\mu$. Reconstruct the image from the truncated blocks, and compute the compression ratio assuming you do not have to store the zeros (the coefficients that were threshold ed to zero), and assume you don't need to store the singular vectors (the setting is that you learn good singular vectors, and then share them between the encoder and decoder, so only the coefficients must be transmitted/stored). How does this compare with the block-based method in this notebook? \n",
        "#"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}