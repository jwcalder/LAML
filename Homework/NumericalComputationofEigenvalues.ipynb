{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numerical Computation of Eigenvalues\n",
        "\n",
        "This notebook covers the power method and orthogonal iteration for the numerical computation of eigenvalues, with application exercises to computing principle directions in PCA on image data sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Power Method\n",
        "\n",
        "The power method refers to the iteration\n",
        "$$\\mathbf{x}_{k+1} = \\frac{A\\mathbf{x}_k}{\\|A\\mathbf{x}_k \\|},$$\n",
        "which, under certain conditions on the matrix $A$ and initial vector $\\mathbf{x}_0$ converges to the dominant eigenvector of $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise (small matrix)\n",
        "\n",
        "Use the power method to compute the top eigenvector of the matrix\n",
        "$$A = \\begin{pmatrix}\n",
        "2&-1&0&-1\\\\\n",
        "-1&2&-1&0\\\\\n",
        "0&-1&2&-1\\\\\n",
        "-1&0&-1&2\n",
        "\\end{pmatrix}.$$\n",
        "Check your result against the output of `numpy.linalg.eig`. How many iterations do you need for an accurate result?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[2,-1,0,-1],[-1,2,-1,0],[0,-1,2,-1],[-1,0,-1,2]])\n",
        "print(\"A=\",A)\n",
        "\n",
        "vals,vecs = np.linalg.eig(A)\n",
        "print('Eigenvalues=',vals)\n",
        "print('Eigenvectors=',vecs) #Columns are eigenvalues\n",
        "\n",
        "#Power method code\n",
        "x = np.random.randn(4,1) #Random initial vector\n",
        "\n",
        "#Insert your code here\n",
        "\n",
        "\n",
        "\n",
        "print('Power Method')\n",
        "print('Eigenvalue: ',...)\n",
        "print('Eigenvector: ',...)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise (random matrix)\n",
        "\n",
        "Create a random $n\\times n$ positive definite symmetric matrix with $n=100$ and compute the top eigenvector with the power method. Compare to `scipy.sparse.linalg.eigsh`. How many iterations do you need for an accurate result?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy import sparse\n",
        "\n",
        "n=100\n",
        "B = np.random.rand(n,n)\n",
        "A = B.T@B #Creates a random positive definite Gram matrix\n",
        "vals,vecs = sparse.linalg.eigsh(A,k=1,which='LM')\n",
        "print('Eigenvalue=',vals[0]) #Eigenvector too long to print\n",
        "print('Eigenvector=',vecs.flatten())\n",
        "\n",
        "#Power method code\n",
        "x = np.random.randn(n,1) #Random initial vector\n",
        "\n",
        "#Insert your code here\n",
        "\n",
        "\n",
        "print('Power Method')\n",
        "print('Eigenvalue: ',...)\n",
        "print('Eigenvector: ',...)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise (Eigenface)\n",
        "\n",
        "Use the power method to compute the top principal direction for the Olivetti face dataset. We first install the [GraphLearning](https://github.com/jwcalder/GraphLearning), and then load and display the Olivetti face images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install -q graphlearning"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "from sklearn import datasets\n",
        "\n",
        "ds = datasets.fetch_olivetti_faces()\n",
        "data = ds['data']\n",
        "labels = ds['target']\n",
        "\n",
        "gl.utils.image_grid(data, n_rows=10, n_cols=15, title='Some faces', fontsize=26)\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(np.unique(labels))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we compute the covariance matrix and the top principle direction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import sparse\n",
        "\n",
        "#Centered covariance matrix\n",
        "mean_face = np.mean(data,axis=0)\n",
        "X = data - mean_face\n",
        "M = X.T@X\n",
        "\n",
        "#Use eigsh to get subset of eigenvectors\n",
        "#('LM'=largest magnitude, k=1 eigenvectors)\n",
        "vals, vecs = sparse.linalg.eigsh(M, k=1, which='LM')\n",
        "\n",
        "#Display the top principal component images\n",
        "n = len(mean_face)\n",
        "m = int(np.sqrt(len(mean_face)))\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(mean_face,(m,m)),cmap='gray')\n",
        "plt.title('Mean Face')\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(vecs[:,0],(m,m)),cmap='gray')\n",
        "plt.title('Top principal direction')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the top principle component of the face data set (the top eigenface) using the power method on the covariance matrix $M$. Print the approximate eigenvalue $\\mathbf{x}_k^TM\\mathbf{x_k}$ and iterate until this stabilizes. How many iterations are required?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Power method code\n",
        "x = np.random.randn(n,1) #Random initial vector\n",
        "\n",
        "#Insert your code here\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(x,(m,m)),cmap='gray')\n",
        "plt.title('Top principal direction (power method)')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "Repeat the same exercise except with one of the digits from the MNIST data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "\n",
        "data,labels = gl.datasets.load('mnist')\n",
        "gl.utils.image_grid(data, n_rows=10, n_cols=15, title='Some MNIST images', fontsize=26)\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(np.unique(labels))\n",
        "\n",
        "#Insert code here\n",
        "ind = labels == 3 #Use only 3's\n",
        "mean_digit = np.mean(data[ind,:],axis=0)\n",
        "X = data[ind,:] - mean_digit\n",
        "M = X.T@X\n",
        "\n",
        "#Display the top principal component image\n",
        "n = len(mean_digit)\n",
        "m = int(np.sqrt(len(mean_digit)))\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(mean_digit,(m,m)),cmap='gray')\n",
        "plt.title('Mean Digit')\n",
        "\n",
        "#Power method code\n",
        "x = np.random.randn(n,1) #Random initial vector\n",
        "\n",
        "#Insert your code here\n",
        "\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(np.reshape(x,(m,m)),cmap='gray')\n",
        "plt.title('Top principal direction (power method)')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Orthogonal Iteration\n",
        "\n",
        "To compute the top $k$ eigenvectors, we use orthogonal iteration, which generalizes the power method to task of computing multiple top eigenvectors. The orthogonal iteration starts from a random $n\\times k$ matrix $Q_0$ and iterates\n",
        "$$Q_{k+1}R_{k+1} = AQ_k,$$\n",
        "where the left hand side is the QR-factorization of the right hand side. In particular, $Q_k$ for $k\\geq 1$ has orthonormal columns and $R_k$ is upper triangular."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise (small matrix)\n",
        "\n",
        "Use the orthogonal iteration to compute all eigenvectors and eigenvalues of the matrix\n",
        "$$A = \\begin{pmatrix}\n",
        "2&-1&0&-1\\\\\n",
        "-1&2&-1&0\\\\\n",
        "0&-1&2&-1\\\\\n",
        "-1&0&-1&2\n",
        "\\end{pmatrix}.$$\n",
        "Check your result against the output of `numpy.linalg.eig`. How many iterations do you need for an accurate result? You can use `np.linalg.qr` for QR-factorization.\n",
        "\n",
        "Recall that the columns of $Q_k$ converge to the top $k$ eigenvectors of $A$, while the diagonal entries of $R$ contain the eigenvalues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[2,-1,0,-1],[-1,2,-1,0],[0,-1,2,-1],[-1,0,-1,2]])\n",
        "print(\"A=\",A)\n",
        "\n",
        "vals,vecs = np.linalg.eig(A)\n",
        "print('Eigenvalues=',vals)\n",
        "print('Eigenvectors=',vecs) #Columns are eigenvalues\n",
        "\n",
        "#Orthogonal iteration (Insert Code Here)\n",
        "\n",
        "\n",
        "\n",
        "print('Orthogonal Iteration')\n",
        "print('Eigenvalues: ',np.diag(R))\n",
        "print('Eigenvectors: ',Q)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise (Eigenfaces)\n",
        "\n",
        "Use the orthogonal iteration method to compute the top $k=10$ principal directions (e.g., eigenfaces) for the Olivetti face dataset. Compare to the output of `scipy.sparse.linalg.eigsh`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphlearning as gl\n",
        "from sklearn import datasets\n",
        "\n",
        "ds = datasets.fetch_olivetti_faces()\n",
        "data = ds['data']\n",
        "labels = ds['target']\n",
        "\n",
        "#Centered covariance matrix\n",
        "mean_face = np.mean(data,axis=0)\n",
        "X = data - mean_face\n",
        "M = X.T@X\n",
        "\n",
        "#Use eigsh to get subset of eigenvectors\n",
        "#('LM'=largest magnitude, k=10 eigenvectors)\n",
        "vals, vecs = sparse.linalg.eigsh(M, k=10, which='LM')\n",
        "vals, P = vals[::-1], vecs[:,::-1] #Returns in opposite order\n",
        "\n",
        "#Insert orthogonal iteration code to compute Q,R below\n",
        "\n",
        "\n",
        "#Display the top principal component images\n",
        "gl.utils.image_grid(P.T, n_rows=1, n_cols=k, title='Top Principal Components (Eigenfaces)', fontsize=26, normalize=True, transpose=False)\n",
        "gl.utils.image_grid(Q.T, n_rows=1, n_cols=k, title='Orthogonal Iteration (Eigenfaces)', fontsize=26, normalize=True, transpose=False)\n",
        "gl.utils.image_grid(-Q.T, n_rows=1, n_cols=k, title='Negated Orthogonal Iteration (Eigenfaces)', fontsize=26, normalize=True, transpose=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "Repeat the same exercise for one of the MNIST digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}